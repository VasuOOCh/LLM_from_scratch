{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c44ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124 = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 256,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53616684",
   "metadata": {},
   "source": [
    "# Transformer Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d151196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf86cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2472fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module) : \n",
    "    def __init__(self,cfg) :\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        shortcut = x\n",
    "        # input dim : [batch_size, num_tokens,emb_dim]\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) \n",
    "        # after the attention mechanism we get context vectors\n",
    "        x = self.drop_shortcut(x)\n",
    "        # dim : [batch_size, num_tokens, emb_dim]\n",
    "        \n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a332a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 7085568\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2,4,768)\n",
    "# input : [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124)\n",
    "out = block(x)\n",
    "\n",
    "total_params = sum(p.numel() for p in block.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "print(x.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823e1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final GPT Model : \n",
    "\n",
    "class GPTModel(nn.Module) :\n",
    "    def __init__(self, cfg) :\n",
    "        super().__init__();\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_idx) : \n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        # seq_len == number of tokens\n",
    "        tok_embeds = self.token_emb(in_idx)\n",
    "        # assume a input has a 4 token : \n",
    "        # so the positions of the 4 tokens are 0,1,2,3 (torch.arange)\n",
    "        # pos_emb will find positional embedding for the 4 positions\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        # x ==> [batch_size, num_tokens, emb_dim]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        # x ==> [batch_size, num_tokens, emb_dim]\n",
    "        logits = self.out_head(x)\n",
    "        # logits ==> [batch_size, num_tokens, vocab_size]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e60908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.4708,  0.5737, -0.5967,  ...,  0.2019, -0.5665,  0.1800],\n",
      "         [-0.3895, -0.1978, -0.8885,  ...,  0.2242, -1.2341,  0.1752],\n",
      "         [ 0.6973, -0.3432, -0.6080,  ...,  0.3747, -0.6967,  0.1088],\n",
      "         [-0.2962, -0.6957, -1.1371,  ...,  0.3579,  0.3058, -0.2915]],\n",
      "\n",
      "        [[-0.1514,  0.3329, -0.9740,  ..., -0.1368, -0.6974, -0.1851],\n",
      "         [-0.4894, -0.3492, -0.9759,  ...,  0.2951, -0.3396,  0.2109],\n",
      "         [ 0.5082, -0.1425,  0.2549,  ...,  0.1618,  0.1304, -0.3092],\n",
      "         [-0.4146, -0.0514, -0.5187,  ..., -0.1869, -0.1303, -0.4969]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "batch = torch.tensor([[6109, 3626, 6100,  345],\n",
    "        [6109, 1110, 6622,  257]])\n",
    "print(batch)\n",
    "out = model(batch)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be587c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output shape [batch_size, num_tokens, vocab_size] represents that\n",
    "# for each input,there are num_tokens tokens, and for each token,\n",
    "# there are 50,000 words to look upon, and output for each token, \n",
    "# the ouput is from one of the 50,000 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12cf8d",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "073abb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162419712\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c32287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.token_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bc176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123822336\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(total_params_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85302f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size is 619.58 MB\n"
     ]
    }
   ],
   "source": [
    "# Weight tying :\n",
    "#  GPT-2 architecture is reusing the weights from the token \n",
    "# embedding layer in its output layer.\n",
    "\n",
    "\n",
    "# Memory : \n",
    "# each param : 32 bit float : 4 BYTES\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size is {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c151f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size) :\n",
    "    # idx is (batch_size, num_tokens)\n",
    "    \n",
    "    for _ in range(max_new_tokens) :\n",
    "        # crop the current context if it exceeds the supported context size :\n",
    "        # from last\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # the above applies cropping for the last dimension only\n",
    "        \n",
    "        with torch.no_grad() : \n",
    "            logits = model(idx_cond)\n",
    "        # logits : [batch_size, num_tokens, 50,000 tokens]\n",
    "            \n",
    "        # extract the last one\n",
    "        logits = logits[:,-1, :]\n",
    "#         print(logits.shape)\n",
    "        # [batch_size, vocab_size]\n",
    "        # this represents : there are batch_size inputs in a given batch\n",
    "        # and for each input, there are 50,000 words available\n",
    "        \n",
    "        # probs :\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        \n",
    "        idx_next = torch.argmax(probs, dim = -1, keepdim = True)\n",
    "#         print(idx_next)\n",
    "#         print(idx_next.shape)\n",
    "        # idx_next : [batch_size, 1]\n",
    "        # for every input there is 1 ouput ready\n",
    "        idx = torch.cat((idx, idx_next),dim = -1)\n",
    "        # (batch_size, n_tokens + 1)\n",
    "        \n",
    "        # final output : [batch_size, num_tokens + n]\n",
    "        \n",
    "    return idx\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feacee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   314,   716]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "start_context = \"Hello, I am\"\n",
    "encoded = torch.tensor(tokenizer.encode(start_context)).unsqueeze(0)\n",
    "print(encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89b513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620, 34991]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model,\n",
    "    idx = encoded,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124[\"context_length\"]\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba17963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Laur inhab DistrinetalkQueue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(dim = 0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d9b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer) :\n",
    "    encoded = tokenizer.encode(text,allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    # [batch_size, num_tokens] OR [no. of batches, batch_size]\n",
    "    \n",
    "    return encoded_tensor\n",
    "\n",
    "def tokens_ids_to_text(token_ids, tokenizer) :\n",
    "    # [batch_size, n_tokens + n(new tokens)]\n",
    "    flat = token_ids.squeeze(0);\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens= 10,\n",
    "    context_size = GPT_CONFIG_124[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(tokens_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd9f427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the loss : \n",
    "inputs = torch.tensor([[16833, 3626, 6100], #\"Every effort moves\"\n",
    "                      [40, 1107, 588]]) \n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                       [1107, 588, 11311]]) # Effort moves you\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0da9a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad() :\n",
    "    logits = model(inputs)\n",
    "# print(logits.shape)\n",
    "\n",
    "probs = torch.softmax(logits, dim = -1)\n",
    "out = torch.argmax(probs, dim = -1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf6f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1 :  effort moves you\n",
      "Targets batch 2 :  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1 : {tokens_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Targets batch 2 : {tokens_ids_to_text(out[0], tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262fbdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss :\n",
    "\n",
    "# this is easy bro !! Just chill out for now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84c46d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0,1,2], targets[text_idx]]\n",
    "target_probs_1\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0,1,2], targets[text_idx]]\n",
    "\n",
    "# target_probs_2\n",
    "\n",
    "# the above are the probalitites of the target tokens in the softmaxed\n",
    "# logits(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1da153b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute the log of all probs :\n",
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f6c26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Avg hese: \n",
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(avg_log_probs)\n",
    "# goal is to make the avg log probs as large as possible\n",
    "# the largest possible val due to log : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68d7902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probs = avg_log_probs * -1\n",
    "print(neg_avg_log_probs)\n",
    "## Now we have to minimize this as close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9093503",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file :\n",
    "    text_data = file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "047305cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it for me! The Strouds stand alone, and happen once--but there\\'s no exterminating our kind of art.\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[-99:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13b90024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(total_characters)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28610286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset) : \n",
    "    def __init__(self, txt, tokenizer, max_length, stride) : \n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for i in range(0,len(token_ids) - max_length, stride) :\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self) : \n",
    "        return len(self.input_ids)\n",
    "        \n",
    "    def __getitem__(self, idx) : \n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53660731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "def create_dataloader_v1(txt, batch_size = 4, max_length = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0) : \n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    \n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    \n",
    "    # Dataloader : \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "    \n",
    "    return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b852fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 256]), torch.Size([4, 256]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(text_data)\n",
    "\n",
    "X, y = next(iter(dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c551cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test \n",
    "train_ratio = 0.90\n",
    "split_idx = int(len(text_data)*train_ratio)\n",
    "\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124[\"context_length\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124[\"context_length\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a7f58e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Number of batches :  9\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_loader : \n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "print(\"validation loader\")\n",
    "for X,y in val_loader : \n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "print(\"Number of batches : \", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ad0cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device) : \n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None) : \n",
    "    total_loss = 0.\n",
    "    \n",
    "    if len(data_loader) == 0 : \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None : \n",
    "        num_batches = len(data_loader)\n",
    "    else : \n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader) : \n",
    "        if i < num_batches : \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else :\n",
    "            break\n",
    "    return total_loss / num_batches # returning the average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dc70ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "820e777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss :  10.987583796183268\n",
      "Validation loss :  10.981104850769043\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad() : \n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss : \", train_loss)\n",
    "print(\"Validation loss : \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbebaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding the training loop of the GPT 2 : \n",
    "\n",
    "def train_model_simple(model, train_loader, test_loader, optimizer, device, num_epochs,\n",
    "                      eval_freq, eval_iter, start_context, tokenizer) : \n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    \n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs) :\n",
    "        model.train() # training mode :\n",
    "        \n",
    "        # strict training :\n",
    "        for input_batch, target_batch in train_loader : \n",
    "            optimizer.zero_grad() # reset the gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # update the loss gradients\n",
    "            optimizer.step() #update the model weights\n",
    "            tokens_seen += input_batch.numel() # returns the total tokens in input_batch\n",
    "            global_step += 1\n",
    "            \n",
    "            # optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch : {epoch} (Step {global_step:06d}) :\")\n",
    "                print(f\"Train loss {train_loss:.3f}, Val loss : {val_loss:.3f}\")\n",
    "            \n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2cfdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter) : \n",
    "    model.eval()\n",
    "    with torch.no_grad() : \n",
    "        train_loss = calc_loss_loader(train_loader,model, device, num_batches = eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba26c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    # encoded : [batch_size = 1, num_tokens]\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = tokens_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1216e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 (Step 000000) :\n",
      "Train loss 9.825, Val loss : 9.931\n",
      "Epoch : 0 (Step 000005) :\n",
      "Train loss 7.924, Val loss : 8.341\n",
      "Every effort moves you,,,,,,,,,,,,,,.                                   \n",
      "Epoch : 1 (Step 000010) :\n",
      "Train loss 6.587, Val loss : 7.044\n",
      "Epoch : 1 (Step 000015) :\n",
      "Train loss 5.987, Val loss : 6.591\n",
      "Every effort moves you, the, the, the, the, the, the, the. \", the,,, the,, the,,, the,, the, and, the, the,, the, the, the,, the,\n",
      "Epoch : 2 (Step 000020) :\n",
      "Train loss 15.786, Val loss : 15.871\n",
      "Epoch : 2 (Step 000025) :\n",
      "Train loss 5.587, Val loss : 6.444\n",
      "Every effort moves you.  \"--. I had. I had been. G. I had, and I had. Gis, and, and. I had. I had to the his his the--, and, and--. Gis. I\n",
      "Epoch : 3 (Step 000030) :\n",
      "Train loss 5.026, Val loss : 6.349\n",
      "Epoch : 3 (Step 000035) :\n",
      "Train loss 4.695, Val loss : 6.247\n",
      "Every effort moves you, I was, I had the of the to the picture. \"I had to the picture, I was, I had to me, I had the the of the, I had the picture to the, I had the, I had the\n",
      "Epoch : 4 (Step 000040) :\n",
      "Train loss 4.131, Val loss : 6.233\n",
      "Every effort moves you know the                                      \", and, and, and he was his\n",
      "Epoch : 5 (Step 000045) :\n",
      "Train loss 3.500, Val loss : 6.195\n",
      "Epoch : 5 (Step 000050) :\n",
      "Train loss 3.135, Val loss : 6.176\n",
      "Every effort moves you know the fact, and pushed one of the donkey, and Mrs.                            \"I turned, I, I had\n",
      "Epoch : 6 (Step 000055) :\n",
      "Train loss 2.705, Val loss : 6.173\n",
      "Epoch : 6 (Step 000060) :\n",
      "Train loss 2.050, Val loss : 6.185\n",
      "Every effort moves you?\"     I glanced after him, and a little of a and in the picture, with a little, the fact, in the moment--as Jack himself, as his pictures's his pictures, and down the room, with a\n",
      "Epoch : 7 (Step 000065) :\n",
      "Train loss 1.700, Val loss : 6.222\n",
      "Epoch : 7 (Step 000070) :\n",
      "Train loss 1.308, Val loss : 6.172\n",
      "Every effort moves you?\" \"I didn't you know it--I turned the his last word.    \"I didn't know. \"Oh, and I had a little him--and I had the, and down the room, I had\n",
      "Epoch : 8 (Step 000075) :\n",
      "Train loss 1.060, Val loss : 6.294\n",
      "Epoch : 8 (Step 000080) :\n",
      "Train loss 0.869, Val loss : 6.360\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the honour being _mine_--because he didn't want\n",
      "Epoch : 9 (Step 000085) :\n",
      "Train loss 0.597, Val loss : 6.427\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 0.50 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f880387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b78531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Pytorch ENV",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
